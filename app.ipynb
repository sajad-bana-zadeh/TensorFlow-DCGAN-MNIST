{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1796f55-2441-4b18-9d7e-19d5987e9889",
   "metadata": {},
   "source": [
    "## RUN in localhost\n",
    "- voila app.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50061be-c8ef-4e4a-a486-92484bb355f7",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3285df7d-ae6a-45de-8e3d-781bf7df7ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 13:07:58.526887: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-21 13:07:58.765891: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-21 13:07:58.969668: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753090679.158625    6132 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753090679.204915    6132 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753090679.596523    6132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753090679.596577    6132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753090679.596584    6132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753090679.596590    6132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os # For checking if file exists\n",
    "import matplotlib.pyplot as plt # For plot\n",
    "import numpy as np  # For saving/loading array data in .npz format\n",
    "import tensorflow as tf  # To download the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75052850-d9fe-4aa4-9fef-8b7b38b648ca",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cccaf9a-a97d-4081-a76e-72b9785f530c",
   "metadata": {},
   "source": [
    "## Load or Download and save dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f3e5d8-2dac-4bc8-b541-5d03f6ef1c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'dataset/mnist_keras_saved.npz'  # Define the filename to save/load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01b2034f-ea1d-42e6-96c0-1b10d33107db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MNIST data from local file.\n"
     ]
    }
   ],
   "source": [
    "# Check if the MNIST data file already exists locally\n",
    "if not os.path.exists(DATA_FILE):\n",
    "    # If file doesn't exist, download the dataset from TensorFlow\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # Save the loaded data arrays into a compressed .npz file for future use\n",
    "    np.savez(DATA_FILE, x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
    "    print(\"Downloaded and saved MNIST data.\")\n",
    "else:\n",
    "    # If the file exists, load the dataset arrays directly from the saved .npz file\n",
    "    with np.load(DATA_FILE) as data:\n",
    "        x_train = data['x_train']  # Load training images\n",
    "        y_train = data['y_train']  # Load training labels\n",
    "        x_test = data['x_test']    # Load test images\n",
    "        y_test = data['y_test']    # Load test labels\n",
    "    print(\"Loaded MNIST data from local file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "263885b3-2409-4e4d-bfad-8eb8ddbec88f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: (60000, 28, 28), \t Test samples: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Print the number of samples in training and test sets to verify loading\n",
    "print(f\"Train samples: {x_train.shape}, \\t Test samples: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81cde66-bca7-460e-9fd3-3cb95bfb5355",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b8d54-c76c-4b5a-87c3-d2f477977f9d",
   "metadata": {},
   "source": [
    "## Plot a sample from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f05d51b6-b9c7-42e4-b1a2-e4661fd81340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sample in traning set: 60000\n",
      "Random choice: 9868, \t Value this No. in datase: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of sample in traning set: {x_train.shape[0]}\")\n",
    "i = np.random.randint(0, x_train.shape[0])\n",
    "print(f\"Random choice: {i}, \\t Value this No. in datase: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09611ad2-9deb-444a-a528-cee9f9744f3e",
   "metadata": {},
   "source": [
    "- x_train: is a NumPy array of shape (60000, 28, 28) which means you have 60,000 samples.\n",
    "- Each sample is a 28x28 matrix (likely grayscale image data, e.g., MNIST digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be1169f-f6fe-4107-b67a-e1cc09abc4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[i], cmap='gray');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5284a02-15cd-444f-9553-16aabfe05614",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d618c58a-bb59-4bc2-b6c2-dc94552ab189",
   "metadata": {},
   "source": [
    "## Reshape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "436de1f8-bd0f-4646-88b6-14ded9b9bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90c0a13e-0bbc-4f0e-9243-ea28165e630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: (60000, 28, 28, 1), \t Test samples: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Print the number of samples in training and test sets after reshape\n",
    "print(f\"Train samples: {x_train.shape}, \\t Test samples: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eba6314-cbd4-4574-a313-96aabf42e7d3",
   "metadata": {},
   "source": [
    "Reshape:\n",
    "- Reshaped the data to (60000, 28, 28, 1).\n",
    "- Added a new final dimension with size 1. (channel size) , ( images were grayscale, grayscale = 1, RGB = 3 )\n",
    "- This is commonly done to make the data compatible with convolutional neural networks (CNNs) in Keras or TensorFlow, where images typically have a channel dimension.\n",
    "- Since the original images were grayscale, they have only 1 channel, so add that channel dimension explicitly.\n",
    "- Also converted the data type to float32 for neural network input, as most frameworks prefer float data types over integers.\n",
    "\n",
    "\n",
    "Summary:\n",
    "- Original shape: (num_samples, height, width) = (60000, 28, 28)\n",
    "- New shape: (num_samples, height, width, channels) = (60000, 28, 28, 1)\n",
    "\n",
    "This reshaping prepares the data for CNN layers that expect 4D input tensor with shape (batch_size, height, width, channels)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed79430d-1bff-406a-bbbd-48d47acf37de",
   "metadata": {},
   "source": [
    "## Min and Max value in color range in grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4383161-0e91-43ab-870c-59c48084c104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: 0.0 \t Min value: 255.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max value: {x_train[0].min()} \\t Min value: {x_train[0].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40987e44-1887-401e-b016-53d0dd688477",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b7c99-59dd-450b-bad7-f97c42e59748",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d624ed-8d57-4844-a9f3-43e46b7e7d96",
   "metadata": {},
   "source": [
    "Normalize:\n",
    "- Convert value 0,255 to -1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa0071e-78bb-4f13-93c8-df3b41d45200",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train -127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c1593d7-b7fb-4e0e-8a3b-28fd442055ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: -1.0 \t Min value: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max value: {x_train[0].min()} \\t Min value: {x_train[0].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb1315d-0cc0-4fa6-904d-b6220417ba58",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aaf539-22e6-4d8d-bc29-4a8896b1fbed",
   "metadata": {},
   "source": [
    "## Convert type dataset to tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1db3397-c892-46fd-946f-b569e578404d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_pic_in_each_batch: 234\n"
     ]
    }
   ],
   "source": [
    "buffer_size = 60000\n",
    "batch_size = 256\n",
    "number_of_pic_in_each_batch = buffer_size // batch_size\n",
    "print(f\"number_of_pic_in_each_batch: {number_of_pic_in_each_batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca163b-3ab0-40fe-85c1-90c0196bbed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
